{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word prediction in historical linguistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:07:51.388051Z",
     "start_time": "2019-08-08T15:07:14.853998Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-06 19:23:55,912 [INFO] Successfully changed parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing program...\n",
      "Loading phonetic feature matrix...\n",
      "Generating all language pairs...\n",
      "Training corpus:\n",
      " - Loading dataset and performing necessary conversion/tokenization.\n",
      "Using existing wordlist file, nothing is generated.\n",
      " - Detect cognates in entire dataset using LexStat.\n",
      "Using existing cognates file output/northeuralex-asjp-cognates.tsv, nothing is generated.\n",
      "Train corpus is valtest corpus.\n",
      "Creating feature matrix for this specific language pair...\n",
      "Converting training corpus TSV file to data matrix...\n",
      "Converting val/test corpus TSV file to data matrix...\n",
      "USE TRAIN M/S\n",
      "Dividing into training, validation and test set...\n",
      "Train/val/test sizes: 711|0|0\n",
      "Train/val/test sizes: 0|236|236\n",
      "Filtering val/test sets on cognates...\n",
      "Val/test sizes after cognate filtering: 159|139\n",
      "Done loading data.\n"
     ]
    }
   ],
   "source": [
    "from util import init\n",
    "from dataset import data\n",
    "from util.config import config\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "lang_family_dict = {\n",
    "\"slav\": [\"ces\", \"bul\", \"rus\", \"bel\", \"ukr\", \"pol\", \"slk\", \"slv\", \"hrv\"],\n",
    "\"ger\": [\"swe\", \"isl\", \"eng\", \"nld\", \"deu\", \"dan\", \"nor\"]\n",
    "}\n",
    "\n",
    "# As user, you can either set separate languages or a language family\n",
    "languages = [\"nld\",\"deu\"]\n",
    "lang_family = None\n",
    "\n",
    "\n",
    "if lang_family:\n",
    "    languages = lang_family_dict[lang_family]\n",
    "\n",
    "options, distances_path, baselines_path = init.initialize_program()\n",
    "(results_path, output_path_cognates_train, output_path_cognates_valtest,\n",
    "context_vectors_path, subs_sp_path, subs_st_path, lang_pairs, train, val, test, max_len, \n",
    "conversion_key, voc_size, feature_matrix_phon) = data.load_data(train_corpus=\"northeuralex\",\n",
    "                                                               valtest_corpus=\"northeuralex\",\n",
    "                                                               languages=languages,  \n",
    "                                                               input_type=\"asjp\", \n",
    "                                                               options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize encoding\n",
    "Visualize the representation of phonemes in the embedding encoding, as PCA and as hierarchically clustered tree. Compare them to the phonetic feature matrix from Brown (2008)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T14:42:48.160590Z",
     "start_time": "2019-08-08T12:37:17.651Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import data\n",
    "from visualize import visualize\n",
    "from tree import cluster\n",
    "from util.config import config\n",
    "\n",
    "tree_style = config[\"ete_tree_style\"]\n",
    "\n",
    "print(\"Phonetic matrix from Brown (2008):\")\n",
    "# Perform PCA on phonetic feature matrix from Brown (2008)\n",
    "phon_matrix_red, phon_phonemes = visualize.dim_reduction(feature_matrix_phon)\n",
    "# Visualize phonetic feature PCA using plot\n",
    "visualize.visualize_encoding(phon_matrix_red, phon_phonemes, \"phonetic-pca\")\n",
    "# Hierarchically cluster distances between phonemes in phonetic feature matrix\n",
    "tree = cluster.cluster_phonemes_encoding(feature_matrix_phon, phon_phonemes, \"phonetic\")\n",
    "\n",
    "display(tree.render(\"%%inline\", tree_style=tree_style))\n",
    "\n",
    "for lang_pair in lang_pairs:\n",
    "    lang_a = lang_pair[0]\n",
    "    print(f\"Embedding for {lang_a}:\")\n",
    "    # Create embedding for every first language in language pair\n",
    "    emb_matrix = data.create_embedding(lang_a, [output_path_cognates_train, output_path_cognates_valtest])\n",
    "    # Perform PCA on embedding matrix\n",
    "    emb_matrix_red, emb_phonemes = visualize.dim_reduction(emb_matrix)\n",
    "    # Visualize embedding PCA using plot\n",
    "    visualize.visualize_encoding(emb_matrix_red, emb_phonemes, f\"embedding-{lang_pair[0]}-pca\")\n",
    "    \n",
    "    # Hierarchically cluster distances between phonemes in embedding matrix\n",
    "    tree = cluster.cluster_phonemes_encoding(emb_matrix, emb_phonemes, f\"embedding-{lang_pair[0]}\")\n",
    "    display(tree.render(\"%%inline\", tree_style=tree_style))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Close-up: constrast occurrences of phonemes in data\n",
    "Interesting patterns in the phoneme encoding visualizations, can be looked up in the data. In the Dutch embedding encoding, we saw that *t* and *d*, closely related phonemes, are quite remote in the embedding space. How do the words with *t* and *d*, on which the embedding encoding is based, look in Dutch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lang = \"nld\"\n",
    "# Read in TSV file with data\n",
    "df = pd.read_csv(output_path_cognates_train, sep=\"\\t\", engine=\"python\", skipfooter=3, index_col=False)\n",
    "df_lang = df[df[\"DOCULECT\"] == lang]\n",
    "\n",
    "for phoneme in [\"d\", \"t\"]:\n",
    "    print(phoneme)\n",
    "    words_with_phoneme = df_lang[df_lang[\"ASJP\"].str.contains(phoneme)]\n",
    "    total = len(words_with_phoneme)\n",
    "    print(f\"Total number of occurrences: {total}\")\n",
    "    \n",
    "    # Compute locations of phonemes in word\n",
    "    locations = df_lang[\"ASJP\"].str.find(phoneme)\n",
    "    locations = locations[locations != -1]\n",
    "    # Compute relative frequencies\n",
    "    locations_relfreq = locations.value_counts(normalize=True)\n",
    "    print(\"Relative frequencies of locations:\")\n",
    "    print(locations_relfreq)\n",
    "    # Look up words with most frequent location\n",
    "    most_freq_location = int(locations.mode())\n",
    "    words_in_most_freq_loc = words_with_phoneme[words_with_phoneme[\"ASJP\"].str.find(phoneme) == most_freq_location]\n",
    "    print(f\"Words with {phoneme} where {phoneme} has most frequent location in word ({most_freq_location}):\")\n",
    "    print(words_in_most_freq_loc)\n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "#words_list = list(df_lang[\"TOKENS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Show number of cognates in training data\n",
    "Show the number of cognate word pairs per language pair in the training data, and calculate cliques of languages with a minimum of 100 shared cognates. These cliques can later be used, to have a group of languages with a large shared number of cognates, to perform prediction on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T14:42:48.156995Z",
     "start_time": "2019-08-08T12:36:42.898Z"
    }
   },
   "outputs": [],
   "source": [
    "cog_per_lang, cliques = data.compute_n_cognates(lang_pairs, output_path_cognates_train, langs=languages, cognates_threshold=100)\n",
    "print(\"Cognates per language: \")\n",
    "print((cog_per_lang))\n",
    "print(\"Cliques: \")\n",
    "for c in cliques:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise word prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word prediction using structured perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T14:42:48.158867Z",
     "start_time": "2019-08-08T12:37:12.451Z"
    }
   },
   "outputs": [],
   "source": [
    "from prediction import prediction\n",
    "\n",
    "for lang_pair in lang_pairs:\n",
    "    lang_a, lang_b = lang_pair\n",
    "    print(\"Performing structured perceptron word prediction for pair (\" + lang_a + \", \" + lang_b + \")\")\n",
    "    prediction.word_prediction_seq(lang_a, lang_b, train[lang_pair], val[lang_pair], test[lang_pair], conversion_key[lang_pair], results_path[lang_pair], distances_path + \".txt\", config)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word prediction using encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T14:42:48.157919Z",
     "start_time": "2019-08-08T12:37:07.979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing RNN word prediction for pair (nld, deu)\n",
      "Create RNN instance.\n",
      "Building network ...\n",
      "Creating loss function...\n",
      "Computing updates ...\n",
      "All params:\n",
      "[enc_bw.W_in_to_updategate, enc_bw.W_hid_to_updategate, enc_bw.b_updategate, enc_bw.W_in_to_resetgate, enc_bw.W_hid_to_resetgate, enc_bw.b_resetgate, enc_bw.W_in_to_hidden_update, enc_bw.W_hid_to_hidden_update, enc_bw.b_hidden_update, enc_bw.hid_init, enc_fw.W_in_to_updategate, enc_fw.W_hid_to_updategate, enc_fw.b_updategate, enc_fw.W_in_to_resetgate, enc_fw.W_hid_to_resetgate, enc_fw.b_resetgate, enc_fw.W_in_to_hidden_update, enc_fw.W_hid_to_hidden_update, enc_fw.b_hidden_update, enc_fw.hid_init, dense_comb.W, dense_comb.b, dec.W_in_to_updategate, dec.W_hid_to_updategate, dec.b_updategate, dec.W_in_to_resetgate, dec.W_hid_to_resetgate, dec.b_resetgate, dec.W_in_to_hidden_update, dec.W_hid_to_hidden_update, dec.b_hidden_update, W, b]\n",
      "Compiling functions ...\n",
      "Training ...\n",
      "0.9992592339914663 3.149856669439072 10.356941389421538 6.5882450499154555\n",
      "0.24917611677391435 11.459952561268981 10.356941389421538 6.5882450499154555\n",
      "0.9941722585021825 5.217660431623474 10.356941389421538 6.5882450499154555\n",
      "0.9942195181008981 5.209470416743327 10.356941389421538 6.5882450499154555\n",
      "0.9565828451106527 7.26442862848021 10.356941389421538 6.5882450499154555\n",
      "0.9969774283927235 4.558321253874625 10.356941389421538 6.5882450499154555\n",
      "0.9942067988395208 5.211681173543524 10.356941389421538 6.5882450499154555\n",
      "0.9855994331399643 6.130958942871944 10.356941389421538 6.5882450499154555\n",
      "0.6388839620494855 9.786417886020576 10.356941389421538 6.5882450499154555\n",
      "0.567014320915096 10.087261482415522 10.356941389421538 6.5882450499154555\n",
      "0.985027427365415 6.17049193994033 10.356941389421538 6.5882450499154555\n",
      "0.9908655252169498 5.670418253509969 10.356941389421538 6.5882450499154555\n",
      "0.9943807057292494 5.181027333761349 10.356941389421538 6.5882450499154555\n",
      "0.9995306529350192 2.6932427940935764 10.356941389421538 6.5882450499154555\n",
      "0.9992403654030271 3.175028278928354 10.356941389421538 6.5882450499154555\n",
      "0.9890114155475384 5.85709247223621 10.356941389421538 6.5882450499154555\n",
      "0.9967878015679569 4.619359051576574 10.356941389421538 6.5882450499154555\n",
      "0.022220247745109042 14.141221898106972 10.356941389421538 6.5882450499154555\n",
      "0.9930082859174397 5.4009281265182185 10.356941389421538 6.5882450499154555\n",
      "0.9988052224905203 3.62834158577777 10.356941389421538 6.5882450499154555\n",
      "0.9927127383779887 5.442627894467651 10.356941389421538 6.5882450499154555\n",
      "0.8501782341524636 8.620941734591218 10.356941389421538 6.5882450499154555\n",
      "0.9974741337927578 4.378299228300027 10.356941389421538 6.5882450499154555\n",
      "0.9477341387994175 7.459210779229099 10.356941389421538 6.5882450499154555\n",
      "0.9943419488616787 5.187939740055887 10.356941389421538 6.5882450499154555\n",
      "0.99958511807092 2.5698397709835246 10.356941389421538 6.5882450499154555\n",
      "0.9807722672025145 6.424954753733404 10.356941389421538 6.5882450499154555\n",
      "0.9880360821892976 5.9431174429328255 10.356941389421538 6.5882450499154555\n",
      "0.9985069511364599 3.851500521458562 10.356941389421538 6.5882450499154555\n",
      "8.924291287673801e-05 19.6810006905273 10.356941389421538 6.5882450499154555\n",
      "0.9990366880216279 3.412771932131679 10.356941389421538 6.5882450499154555\n",
      "0.9992547953648342 3.155835172632779 10.356941389421538 6.5882450499154555\n",
      "0.9989896290417892 3.460514540943938 10.356941389421538 6.5882450499154555\n",
      "0.1507916903103527 12.08534655450512 10.356941389421538 6.5882450499154555\n",
      "0.9979788169564403 4.154892343936656 10.356941389421538 6.5882450499154555\n",
      "0.9993190450269815 3.065608203433404 10.356941389421538 6.5882450499154555\n",
      "0.9991904653459396 3.2387002753790712 10.356941389421538 6.5882450499154555\n",
      "0.997755969401832 4.259706285762026 10.356941389421538 6.5882450499154555\n",
      "0.9983420190379984 3.9564460415121485 10.356941389421538 6.5882450499154555\n",
      "0.9989299722440612 3.5179412993507544 10.356941389421538 6.5882450499154555\n",
      "0.780495989128209 9.088382293441148 10.356941389421538 6.5882450499154555\n",
      "0.9987637275546545 3.662523907482226 10.356941389421538 6.5882450499154555\n",
      "0.9994016823729593 2.936151089986061 10.356941389421538 6.5882450499154555\n",
      "0.9750091002791674 6.693006332280941 10.356941389421538 6.5882450499154555\n",
      "0.9955247948612074 4.952223551032153 10.356941389421538 6.5882450499154555\n",
      "0.9992542527030256 3.156563655777034 10.356941389421538 6.5882450499154555\n",
      "0.9972029734385847 4.4805439665582 10.356941389421538 6.5882450499154555\n",
      "0.9869140128042801 6.033900451511114 10.356941389421538 6.5882450499154555\n",
      "0.1603188711577812 12.012798823977969 10.356941389421538 6.5882450499154555\n",
      "0.9967478822913598 4.631749914575285 10.356941389421538 6.5882450499154555\n",
      "0.9963862087540611 4.73756387509799 10.356941389421538 6.5882450499154555\n",
      "0.9978941398669516 4.196018188962747 10.356941389421538 6.5882450499154555\n",
      "0.9947915654711129 5.104687492457839 10.356941389421538 6.5882450499154555\n",
      "0.03199258614518216 13.766676942615687 10.356941389421538 6.5882450499154555\n",
      "0.9997126925876293 2.2022709459099064 10.356941389421538 6.5882450499154555\n",
      "0.9981879754232114 4.045444549596547 10.356941389421538 6.5882450499154555\n",
      "0.9932031745343493 5.372461799413828 10.356941389421538 6.5882450499154555\n",
      "0.9936441237795758 5.304942045276936 10.356941389421538 6.5882450499154555\n",
      "0.7833008637647223 9.071934444864848 10.356941389421538 6.5882450499154555\n",
      "0.9989302229263618 3.5177067445063566 10.356941389421538 6.5882450499154555\n",
      "0.8925467877741402 8.239917971582592 10.356941389421538 6.5882450499154555\n",
      "0.9995007549655777 2.755027227328091 10.356941389421538 6.5882450499154555\n",
      "0.9425638564117989 7.55901150463107 10.356941389421538 6.5882450499154555\n",
      "5.945391601570884e-06 22.389829603259543 10.356941389421538 6.5882450499154555\n",
      "0.9668665559524614 6.983424067935594 10.356941389421538 6.5882450499154555\n",
      "0.9994561327884802 2.8406799672067806 10.356941389421538 6.5882450499154555\n",
      "0.9991565116444279 3.279820772746329 10.356941389421538 6.5882450499154555\n",
      "0.9991249101284079 3.316632895917855 10.356941389421538 6.5882450499154555\n",
      "0.9975799615616039 4.335392505581025 10.356941389421538 6.5882450499154555\n",
      "0.9984048040519308 3.9177791602123935 10.356941389421538 6.5882450499154555\n",
      "0.9986243157892821 3.769513956919931 10.356941389421538 6.5882450499154555\n",
      "0.9994615634141714 2.8306391419502064 10.356941389421538 6.5882450499154555\n",
      "0.9727592084413115 6.781520350749073 10.356941389421538 6.5882450499154555\n",
      "0.9993685873697719 2.990022022964968 10.356941389421538 6.5882450499154555\n",
      "0.9978128663450314 4.233967492574618 10.356941389421538 6.5882450499154555\n",
      "0.12966358708558368 12.260877903153306 10.356941389421538 6.5882450499154555\n",
      "0.5626924746020001 10.104844803849351 10.356941389421538 6.5882450499154555\n",
      "0.08789835076729341 12.69651178886373 10.356941389421538 6.5882450499154555\n",
      "0.9992601415705815 3.1486298200161067 10.356941389421538 6.5882450499154555\n",
      "0.9986677710369666 3.737372679123831 10.356941389421538 6.5882450499154555\n",
      "0.9995322751832987 2.6897787901687096 10.356941389421538 6.5882450499154555\n",
      "0.9991375228518397 3.3021023344206704 10.356941389421538 6.5882450499154555\n",
      "0.9988451383884641 3.594322159360517 10.356941389421538 6.5882450499154555\n",
      "0.99724763855514 4.464401517017704 10.356941389421538 6.5882450499154555\n",
      "0.9958388249669679 4.8791534615063 10.356941389421538 6.5882450499154555\n",
      "0.9942366340538886 5.206487818345878 10.356941389421538 6.5882450499154555\n",
      "0.9931683207551821 5.377611738875378 10.356941389421538 6.5882450499154555\n",
      "0.9992712752211467 3.133455950173125 10.356941389421538 6.5882450499154555\n",
      "0.9865259012579483 6.0635210394450185 10.356941389421538 6.5882450499154555\n",
      "0.9972462625556158 4.4649027060568 10.356941389421538 6.5882450499154555\n",
      "0.017869853779591167 14.363550074100788 10.356941389421538 6.5882450499154555\n",
      "0.011812309610319987 14.783671864112323 10.356941389421538 6.5882450499154555\n",
      "0.962041513998202 7.124376874747834 10.356941389421538 6.5882450499154555\n",
      "0.9715089506067073 6.827680889036954 10.356941389421538 6.5882450499154555\n",
      "0.9985649440716208 3.8118260199791334 10.356941389421538 6.5882450499154555\n",
      "0.9978602612168163 4.212011899384937 10.356941389421538 6.5882450499154555\n",
      "0.9972867254439691 4.45005930131187 10.356941389421538 6.5882450499154555\n",
      "0.9567168473929494 7.261197390998385 10.356941389421538 6.5882450499154555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993688364451468 5.297912590987167 10.356941389421538 6.5882450499154555\n",
      "0.003125619250381583 16.1219337305236 10.356941389421538 6.5882450499154555\n",
      "0.9979534496128472 4.167390395654662 10.356941389421538 6.5882450499154555\n",
      "0.9992602526572159 3.1484795517761075 10.356941389421538 6.5882450499154555\n",
      "0.9936056969046846 5.311008397256621 10.356941389421538 6.5882450499154555\n",
      "0.9998385807126424 1.6255975128264954 10.356941389421538 6.5882450499154555\n",
      "0.9854812819981575 6.139249970029935 10.356941389421538 6.5882450499154555\n",
      "0.8122365705665314 8.89233256499013 10.356941389421538 6.5882450499154555\n",
      "0.9995515286460105 2.6477242121602798 10.356941389421538 6.5882450499154555\n",
      "0.9927041500746578 5.443814388358862 10.356941389421538 6.5882450499154555\n",
      "0.9979298869682636 4.178861579606862 10.356941389421538 6.5882450499154555\n",
      "0.033696514573546534 13.713024934509777 10.356941389421538 6.5882450499154555\n",
      "0.09440637010577138 12.617923511909513 10.356941389421538 6.5882450499154555\n",
      "0.9987635849972077 3.6626393558904917 10.356941389421538 6.5882450499154555\n",
      "0.9813775705594714 6.392350858686323 10.356941389421538 6.5882450499154555\n",
      "0.9984811439412734 3.8686635797041404 10.356941389421538 6.5882450499154555\n",
      "0.9990960568043058 3.349101705252395 10.356941389421538 6.5882450499154555\n",
      "0.9991043592054394 3.339866307243159 10.356941389421538 6.5882450499154555\n",
      "0.9992510746117332 3.160819400854285 10.356941389421538 6.5882450499154555\n",
      "0.00012990117013755127 19.305548106154497 10.356941389421538 6.5882450499154555\n",
      "0.7577716721286044 9.216440058198746 10.356941389421538 6.5882450499154555\n",
      "0.9966008489601712 4.676116757993452 10.356941389421538 6.5882450499154555\n",
      "0.9893278559603426 5.827552596297527 10.356941389421538 6.5882450499154555\n",
      "0.7979829580457551 8.983206207984862 10.356941389421538 6.5882450499154555\n",
      "0.9805433106284703 6.437025510270641 10.356941389421538 6.5882450499154555\n",
      "0.9955555414124008 4.945298533977556 10.356941389421538 6.5882450499154555\n",
      "0.9987403743498012 3.6812611038876097 10.356941389421538 6.5882450499154555\n",
      "0.9989342475491028 3.513933507561265 10.356941389421538 6.5882450499154555\n",
      "0.9961794222748341 4.793415653352253 10.356941389421538 6.5882450499154555\n",
      "0.9985659494695304 3.8111241691875914 10.356941389421538 6.5882450499154555\n",
      "0.7876770006312755 9.045961978397285 10.356941389421538 6.5882450499154555\n",
      "0.998942337302192 3.5063058043165913 10.356941389421538 6.5882450499154555\n",
      "0.0299230629827907 13.835687254000112 10.356941389421538 6.5882450499154555\n",
      "0.9985860362453922 3.796998008696406 10.356941389421538 6.5882450499154555\n",
      "0.999697788079775 2.2528615829347878 10.356941389421538 6.5882450499154555\n",
      "0.8912941554131795 8.252912436409405 10.356941389421538 6.5882450499154555\n",
      "0.8888570914934396 8.277821756069761 10.356941389421538 6.5882450499154555\n",
      "0.989514569697375 5.809713603527248 10.356941389421538 6.5882450499154555\n",
      "0.9994267375922978 2.893347824233307 10.356941389421538 6.5882450499154555\n",
      "0.9970510663599073 4.5335830278196125 10.356941389421538 6.5882450499154555\n",
      "0.998368006505532 3.940621707387043 10.356941389421538 6.5882450499154555\n",
      "Epoch  1 validation loss = 11.78, distance = 0.65, duration = 140.86\n",
      "0.9979759259108226 4.060730342284615 10.26134713989127 6.2841755817026455\n",
      "0.08693128871645418 12.61304025471164 10.26134713989127 6.2841755817026455\n",
      "0.9505698935563648 7.304845127941731 10.26134713989127 6.2841755817026455\n",
      "0.9895566646573914 5.710054119232272 10.26134713989127 6.2841755817026455\n",
      "0.9404968929914448 7.500967324546095 10.26134713989127 6.2841755817026455\n",
      "0.9802487621513335 6.3567569267733015 10.26134713989127 6.2841755817026455\n",
      "0.9987649845804641 3.5659110950448483 10.26134713989127 6.2841755817026455\n",
      "0.9565633510888333 7.169303650736226 10.26134713989127 6.2841755817026455\n",
      "0.184780786721056 11.745634004470798 10.26134713989127 6.2841755817026455\n",
      "0.11466532146894719 12.305295243982451 10.26134713989127 6.2841755817026455\n",
      "0.8489855300196355 8.534680657191 10.26134713989127 6.2841755817026455\n",
      "0.9729476838679196 6.6787894527486715 10.26134713989127 6.2841755817026455\n",
      "0.9979726984191468 4.062326858521706 10.26134713989127 6.2841755817026455\n",
      "0.9994305385211244 2.791097345956608 10.26134713989127 6.2841755817026455\n",
      "0.999009616968541 3.344919224477333 10.26134713989127 6.2841755817026455\n",
      "0.91794048021504 7.846659422737699 10.26134713989127 6.2841755817026455\n",
      "0.9989268774611162 3.4252382189127473 10.26134713989127 6.2841755817026455\n",
      "0.004325061386877701 15.700341643571472 10.26134713989127 6.2841755817026455\n",
      "0.9979007328470516 4.097281643649024 10.26134713989127 6.2841755817026455\n",
      "0.9977341395811815 4.173814854932532 10.26134713989127 6.2841755817026455\n",
      "0.9787543638164552 6.4312179522488275 10.26134713989127 6.2841755817026455\n",
      "0.9156257795545616 7.877001306280392 10.26134713989127 6.2841755817026455\n",
      "0.9942323408617759 5.111642520148325 10.26134713989127 6.2841755817026455\n",
      "0.8311806459362032 8.667329217227497 10.26134713989127 6.2841755817026455\n",
      "0.9747569770591997 6.607708752622658 10.26134713989127 6.2841755817026455\n",
      "0.9995759513166301 2.496108988453458 10.26134713989127 6.2841755817026455\n",
      "0.781097753762727 8.98927209896798 10.26134713989127 6.2841755817026455\n",
      "0.9032120236275925 8.027912590429525 10.26134713989127 6.2841755817026455\n",
      "0.9971730521237089 4.39562045287367 10.26134713989127 6.2841755817026455\n",
      "5.52756244546777e-06 22.367105239356935 10.26134713989127 6.2841755817026455\n",
      "0.999119856785517 3.2268017506565747 10.26134713989127 6.2841755817026455\n",
      "0.9992278403720819 3.0958003403886463 10.26134713989127 6.2841755817026455\n",
      "0.9989037619816941 3.4465730351708834 10.26134713989127 6.2841755817026455\n",
      "0.00771342915614165 15.11839623132774 10.26134713989127 6.2841755817026455\n",
      "0.9984169513306376 3.814528689367551 10.26134713989127 6.2841755817026455\n",
      "0.9995468374293962 2.562540783814243 10.26134713989127 6.2841755817026455\n",
      "0.9993682079488238 2.8950288806975597 10.26134713989127 6.2841755817026455\n",
      "0.996903744585633 4.486886370144978 10.26134713989127 6.2841755817026455\n",
      "0.9980022037202652 4.047636368378939 10.26134713989127 6.2841755817026455\n",
      "0.9944179655076463 5.07874284748258 10.26134713989127 6.2841755817026455\n",
      "0.25334377858085355 11.342204631801117 10.26134713989127 6.2841755817026455\n",
      "0.993914676457073 5.165575671090803 10.26134713989127 6.2841755817026455\n",
      "0.9984385006927042 3.800801034753324 10.26134713989127 6.2841755817026455\n",
      "0.6317469883439168 9.721628394400133 10.26134713989127 6.2841755817026455\n",
      "0.9788825795621314 6.4250337567343365 10.26134713989127 6.2841755817026455\n",
      "0.999680840625226 2.211846377708445 10.26134713989127 6.2841755817026455\n",
      "0.9988031937105748 3.5344459673689466 10.26134713989127 6.2841755817026455\n",
      "0.9727538070074836 6.686129919032414 10.26134713989127 6.2841755817026455\n",
      "0.011575906195275933 14.708533104365 10.26134713989127 6.2841755817026455\n",
      "0.9996322661829693 2.3535637365331135 10.26134713989127 6.2841755817026455\n",
      "0.9852025761788571 6.062952958249054 10.26134713989127 6.2841755817026455\n",
      "0.9998360837240013 1.5453562969040522 10.26134713989127 6.2841755817026455\n",
      "0.9995064188720967 2.6480175231834298 10.26134713989127 6.2841755817026455\n",
      "0.022510955796779242 14.032332108709232 10.26134713989127 6.2841755817026455\n",
      "0.9995286359904407 2.6019386966647575 10.26134713989127 6.2841755817026455\n",
      "0.9994103890670998 2.825889250362795 10.26134713989127 6.2841755817026455\n",
      "0.9649301298658508 6.946633806556137 10.26134713989127 6.2841755817026455\n",
      "0.9831771769011403 6.1932942772355455 10.26134713989127 6.2841755817026455\n",
      "0.38384140733426203 10.734622060369647 10.26134713989127 6.2841755817026455\n",
      "0.9995721511067617 2.5050346024363677 10.26134713989127 6.2841755817026455\n",
      "0.9377927697900941 7.548289377328736 10.26134713989127 6.2841755817026455\n",
      "0.9996575140415581 2.282409786158934 10.26134713989127 6.2841755817026455\n",
      "0.9273268899988911 7.7150124442700845 10.26134713989127 6.2841755817026455\n",
      "5.689477576535401e-07 24.640823792295777 10.26134713989127 6.2841755817026455\n",
      "0.296525988119936 11.125243210341221 10.26134713989127 6.2841755817026455\n",
      "0.9996738606847051 2.2334874120474457 10.26134713989127 6.2841755817026455\n",
      "0.9995308766156114 2.5971716289510676 10.26134713989127 6.2841755817026455\n",
      "0.9996273258128842 2.36691387051376 10.26134713989127 6.2841755817026455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9988008813673973 3.536378513165234 10.26134713989127 6.2841755817026455\n",
      "0.9985739138725229 3.709952682983713 10.26134713989127 6.2841755817026455\n",
      "0.9847309175272009 6.094808746724785 10.26134713989127 6.2841755817026455\n",
      "0.9995359195487424 2.586358693624391 10.26134713989127 6.2841755817026455\n",
      "0.9705492835559604 6.766203194231308 10.26134713989127 6.2841755817026455\n",
      "0.9990644592841917 3.2878972283459 10.26134713989127 6.2841755817026455\n",
      "0.9993311749880827 2.9520280899750406 10.26134713989127 6.2841755817026455\n",
      "0.0062934103781645415 15.32328600723885 10.26134713989127 6.2841755817026455\n",
      "0.07136653218812058 12.827232233384596 10.26134713989127 6.2841755817026455\n",
      "0.006386605207757082 15.308492471224955 10.26134713989127 6.2841755817026455\n",
      "0.9994652752184647 2.7281236372210627 10.26134713989127 6.2841755817026455\n",
      "0.9974519997757404 4.291451938534551 10.26134713989127 6.2841755817026455\n",
      "0.9992291122602787 3.0941505264411178 10.26134713989127 6.2841755817026455\n",
      "0.999334515397405 2.9470177890335427 10.26134713989127 6.2841755817026455\n",
      "0.9984939242770782 3.7646064808423314 10.26134713989127 6.2841755817026455\n",
      "0.9959163834324302 4.764666847611517 10.26134713989127 6.2841755817026455\n",
      "0.9984016503255817 3.824163132750041 10.26134713989127 6.2841755817026455\n",
      "0.9891788592573854 5.745973672966021 10.26134713989127 6.2841755817026455\n",
      "0.9789844133291923 6.420095803331554 10.26134713989127 6.2841755817026455\n",
      "0.9964719884458387 4.617860523700621 10.26134713989127 6.2841755817026455\n",
      "0.9771734399646924 6.50460775241432 10.26134713989127 6.2841755817026455\n",
      "0.9975770735130156 4.240993829138555 10.26134713989127 6.2841755817026455\n",
      "0.0015019148750293162 16.760858497672327 10.26134713989127 6.2841755817026455\n",
      "0.0007787307918245037 17.41841325929182 10.26134713989127 6.2841755817026455\n",
      "0.8516743772944458 8.51355288277459 10.26134713989127 6.2841755817026455\n",
      "0.9214072637410077 7.799724285203298 10.26134713989127 6.2841755817026455\n",
      "0.9955452962087773 4.852017086107947 10.26134713989127 6.2841755817026455\n",
      "0.9965773354766082 4.5874397442885675 10.26134713989127 6.2841755817026455\n",
      "0.9995278361644583 2.603634891822805 10.26134713989127 6.2841755817026455\n",
      "0.9632548201816202 6.995036207967708 10.26134713989127 6.2841755817026455\n",
      "0.9903206952304141 5.6333083920273825 10.26134713989127 6.2841755817026455\n",
      "0.004826132009705817 15.59021928279904 10.26134713989127 6.2841755817026455\n",
      "0.9978791163143205 4.107547831554597 10.26134713989127 6.2841755817026455\n",
      "0.9992680931342073 3.042222030110272 10.26134713989127 6.2841755817026455\n",
      "0.9643549282894642 6.963498626535974 10.26134713989127 6.2841755817026455\n",
      "0.9998359513118679 1.5461639066909396 10.26134713989127 6.2841755817026455\n",
      "0.9724708219726145 6.69675352932893 10.26134713989127 6.2841755817026455\n",
      "0.5124876982258367 10.211385957156637 10.26134713989127 6.2841755817026455\n",
      "0.9997481819820625 1.9747951072491934 10.26134713989127 6.2841755817026455\n",
      "0.9362179962642264 7.574969865993087 10.26134713989127 6.2841755817026455\n",
      "0.9970269609548111 4.446154005406029 10.26134713989127 6.2841755817026455\n",
      "0.006697682441391372 15.260620644012553 10.26134713989127 6.2841755817026455\n",
      "0.015270323319271813 14.427803010978199 10.26134713989127 6.2841755817026455\n",
      "0.9964669758186137 4.619285353747458 10.26134713989127 6.2841755817026455\n",
      "0.9731188491954221 6.6722662454044555 10.26134713989127 6.2841755817026455\n",
      "0.9983446171192886 3.8592809453841865 10.26134713989127 6.2841755817026455\n",
      "0.9987631183192915 3.5674229467996033 10.26134713989127 6.2841755817026455\n",
      "0.9997160052502201 2.095076368310606 10.26134713989127 6.2841755817026455\n",
      "0.9993776722383747 2.8799260053163054 10.26134713989127 6.2841755817026455\n",
      "7.547097525631975e-05 19.753034075381937 10.26134713989127 6.2841755817026455\n",
      "0.801087462006817 8.868242228304856 10.26134713989127 6.2841755817026455\n",
      "0.9990378183641132 3.316002470293001 10.26134713989127 6.2841755817026455\n",
      "0.9878204826899694 5.86560178811277 10.26134713989127 6.2841755817026455\n",
      "0.4840633691164954 10.325115263393005 10.26134713989127 6.2841755817026455\n",
      "0.916329452072521 7.867858215005215 10.26134713989127 6.2841755817026455\n",
      "0.9968951087704871 4.489680266333253 10.26134713989127 6.2841755817026455\n",
      "0.9994236998062668 2.8030417428551755 10.26134713989127 6.2841755817026455\n",
      "0.9997847188208827 1.8179968698189022 10.26134713989127 6.2841755817026455\n",
      "0.9934013248821834 5.247081292691107 10.26134713989127 6.2841755817026455\n",
      "0.9990696116017259 3.2823695349209587 10.26134713989127 6.2841755817026455\n",
      "0.5135371699137337 10.207185223728105 10.26134713989127 6.2841755817026455\n",
      "0.9986548140544314 3.6514702054211017 10.26134713989127 6.2841755817026455\n",
      "0.0006873250028473669 17.54336288070991 10.26134713989127 6.2841755817026455\n",
      "0.9976341162579333 4.21711217521334 10.26134713989127 6.2841755817026455\n",
      "0.9995222492741792 2.615403549179268 10.26134713989127 6.2841755817026455\n",
      "0.8320238032331866 8.661308373277075 10.26134713989127 6.2841755817026455\n",
      "0.9161872063481691 7.869712087067661 10.26134713989127 6.2841755817026455\n",
      "0.9978512207545555 4.120642840160915 10.26134713989127 6.2841755817026455\n",
      "0.9988608124223197 3.485047055046473 10.26134713989127 6.2841755817026455\n",
      "0.9973454187483797 4.332536893393762 10.26134713989127 6.2841755817026455\n",
      "0.981909734009582 6.267221759348185 10.26134713989127 6.2841755817026455\n",
      "Epoch  2 validation loss = 10.98, distance = 0.65, duration = 152.73\n",
      "Predict and show results.\n",
      "INPUT                TARGET               PREDICTION           DISTANCE\n",
      "tant3                tant3                San3                 0.40\n",
      "til3                 hoGheb3n             lii33                0.88\n",
      "vErkiz3              vEl3n                iii3                 0.80\n",
      "kid3                 hErd3                kin3n                1.00\n",
      "stErkt3              StErk3               Sii33                0.67\n",
      "krEis                kGoic                Gii3                 0.60\n",
      "brur                 bGuda                bGu                  0.40\n",
      "morx3                morg3n               mii33                0.67\n",
      "sam3                 cuzam3n              Sai33                0.71\n",
      "vErxan               fErge3n              iii3                 0.86\n",
      "klim3                klEtan               lii33                0.83\n",
      "bind3l               bind3l               nan3                 0.67\n",
      "link3r               liNka                lii3                 0.60\n",
      "won3                 von3n                vin33                0.40\n",
      "sx3lt                Sult                 Slll                 0.50\n",
      "brand3               bGEn3n               Gai33                0.67\n",
      "ski                  ski                  Siis                 0.75\n",
      "zikzEin              kGaNkzain            Sii33                1.00\n",
      "drain                dGe3n                dai3                 0.60\n",
      "rex3                 Geg3n                Gii3                 0.60\n",
      "sid3r3               citan                Sii33                0.80\n",
      "hElft                hElft3               bbl                  0.83\n",
      "ovErwin3             zig3n                iii3                 0.60\n",
      "fert3x               firciS               iii3                 0.67\n",
      "tek3                 caiS3n               GEi3n                0.50\n",
      "nakt                 nakt                 Sant                 0.50\n",
      "hoNerix              huNGiS               hii3                 0.67\n",
      "wrEiv3               Gaib3n               vii33                0.67\n",
      "zond3                zind3                zan3                 0.40\n",
      "zixvErzam3l3         ziSfErzam3ln         Sai33                0.75\n",
      "hoN3r                huNa                 har                  0.75\n",
      "zom3r                zoma                 zai3                 0.75\n",
      "hart                 hErc                 aart                 0.75\n",
      "b3drix3              b3tGig3n             iii33                0.75\n",
      "drEk                 dGEk                 dara                 0.75\n",
      "hals                 hals                 hali                 0.25\n",
      "pat                  pat                  Son                  1.00\n",
      "spul3                Spil3n               Slll3                0.50\n",
      "hEmt                 hEmt                 mara                 1.00\n",
      "krEip3               kGiS3n               Gii33                0.50\n",
      "b3tal3               b3cal3n              lai33                0.71\n",
      "t3r3x                vida                 iii3                 0.75\n",
      "vex3                 feg3n                fii3                 0.60\n",
      "x3wixt               g3viSt               Sii33                0.83\n",
      "lEid3                loit3n               lii3n                0.33\n",
      "spits                Spic                 Spii                 0.25\n",
      "hev3l                hig3l                hai3l                0.40\n",
      "xord3l               girt3l               Gai3                 0.83\n",
      "b3hers3              b3hErS3n             Gii33                0.88\n",
      "rEn3                 GEn3n                Gii33                0.60\n",
      "bEix3                boig3n               bii33                0.50\n",
      "kis3                 kis3n                kis3n                0.00\n",
      "buzEm                buz3n                bau3                 0.60\n",
      "inslap3              ainSlaf3n            San33                0.67\n",
      "ton                  ton                  con3                 0.50\n",
      "mid3                 mit3                 mii3n                0.40\n",
      "wort3l               vurc3l               vai3                 0.67\n",
      "vremt                fGEmt                lii3                 1.00\n",
      "strom3               StGem3n              Sii33                0.71\n",
      "zid3                 zid3n                Sii3n                0.40\n",
      "slEip3               Slaif3n              Sll33n               0.43\n",
      "yini                 yuni                 yun                  0.25\n",
      "handuk               hantuG               hor                  0.83\n",
      "x3borEnword3         g3boGenvErd3n        Gii33                0.85\n",
      "x3zin                famili               Sii33                0.83\n",
      "rot                  Got                  GGtt                 0.50\n",
      "xEf                  SEf                  Saa                  0.67\n",
      "nat                  nas                  aant                 0.75\n",
      "hem3l                him3l                hai3n                0.60\n",
      "xev3                 geb3n                Sii3                 0.80\n",
      "x3lEit               laut                 Sii33                1.00\n",
      "lex                  ler                  lii3                 0.75\n",
      "wExan                vEge3n               vai3                 0.67\n",
      "vrau                 fGau                 fGt                  0.50\n",
      "stot3                Stos3n               Sti33n               0.33\n",
      "vErbet3r3            fErbEsan             iii3                 1.00\n",
      "b3xin3               anfaN3n              Sii33                0.86\n",
      "vErxet3              fErgEs3n             iii3                 0.88\n",
      "der                  tir                  ded                  1.00\n",
      "stan                 Ste3n                Stat3                0.60\n",
      "kok3                 koG3n                kol33                0.40\n",
      "sxEin3               Sain3n               Sii33n               0.33\n",
      "uv3r                 ufa                  fat                  0.67\n",
      "Eil3                 ail3n                lii33                0.60\n",
      "Eiz3r                aiz3n                vii3                 0.60\n",
      "tal                  ancal                Sala                 0.80\n",
      "sxer3                Gais3n               Sii33                0.67\n",
      "part                 pErt                 aar                  0.75\n",
      "vuts3l               naGuN                fll                  1.00\n",
      "blint                blint                bait                 0.40\n",
      "afsnEid3             abSnaid3n            Sai33                0.56\n",
      "vErbrand3            fErbGEn3n            iii3                 0.89\n",
      "anzin                anze3n               San33                0.67\n",
      "warhEit              varhait              vai                  0.57\n",
      "rEip                 Gaif                 iii3                 0.75\n",
      "vur3                 fitan                fll3                 0.80\n",
      "rur3                 GiG3n                GGi3                 0.60\n",
      "hErfst               hErbst               har                  0.67\n",
      "wEnd3                vEnd3n               vid3                 0.50\n",
      "tuvux3               hincufig3n           kau3n                0.70\n",
      "vex3                 keG3n                fii3                 0.80\n",
      "mEis                 maus                 maia                 0.50\n",
      "x3wer                geveG                Sai3                 1.00\n",
      "vol                  fol                  foll                 0.25\n",
      "blaz3                blaz3n               lai33                0.50\n",
      "stEix3               Staig3n              Sii33                0.57\n",
      "stok                 Stok                 Stos                 0.25\n",
      "morx3                morg3n               mii33                0.67\n",
      "stomp                Stump                Slif3                0.80\n",
      "inwik3l3             ainvik3ln            vii33                0.67\n",
      "reparer3             GepaGiG3n            Gii3                 0.67\n",
      "dri                  dGai                 diit                 0.75\n",
      "dr3p3l               tGop3n               pGl3                 0.67\n",
      "hEld3r               hEl                  aaia                 1.00\n",
      "sx3im                Saum                 Sii33                0.80\n",
      "last                 last                 lltt                 0.50\n",
      "dir                  tir                  diit                 0.75\n",
      "aNelExEnhEit         aNelegEnhait         aaia                 0.75\n",
      "hondErt              hundErt              hont                 0.57\n",
      "rup3                 Guf3n                GGG3                 0.60\n",
      "drom                 tGaum                dii3                 1.00\n",
      "tudEk3               cudEk3n              Gai33                0.86\n",
      "brad3                bGat3n               Gii33                0.67\n",
      "ost3                 ost3n                Sos3                 0.60\n",
      "slik3                Sluk3n               Sli33n               0.33\n",
      "lerar                leGa                 leda                 0.25\n",
      "mar                  nur                  maaa                 1.00\n",
      "xrun                 gGin                 gai3                 0.50\n",
      "hErkEn3              ErkEn3n              hai33                0.86\n",
      "spel3                Spil3n               Slll3n               0.33\n",
      "vErbind3             fErbind3n            iii3                 0.78\n",
      "mart                 mErc                 mata                 0.75\n",
      "arm                  arm                  aamm                 0.50\n",
      "sprek3               SpGES3n              Sii33                0.71\n",
      "stap3                SGait3n              Sta33                0.57\n",
      "zwErm                Svarm                Sai3                 0.60\n",
      "lint                 bant                 lint                 0.50\n",
      "z3                   zi                   zai33                0.60\n",
      "r3is3                GauS3n               Gii33                0.67\n",
      "Average distance: 0.6529499477341204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from prediction import prediction\n",
    "\n",
    "for lang_pair in lang_pairs:\n",
    "    lang_a,lang_b = lang_pair\n",
    "    print(\"Performing RNN word prediction for pair (\" + lang_a + \", \" + lang_b + \")\")\n",
    "    prediction.word_prediction(lang_a, lang_b, (max_len[lang_a], max_len[lang_b]), train[lang_pair], val[lang_pair], test[lang_pair], conversion_key[lang_pair], voc_size, results_path[lang_pair], distances_path + \".txt\", context_vectors_path[lang_pair] + \".p\", config[\"output_encoding\"], config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T14:42:48.159715Z",
     "start_time": "2019-08-08T12:37:14.818Z"
    }
   },
   "outputs": [],
   "source": [
    "from models import baseline\n",
    "\n",
    "# Only ASJP\n",
    "for lang_pair in lang_pairs:\n",
    "    lang_a,lang_b = lang_pair\n",
    "    conv = conversion_key[lang_pair]\n",
    "    sounds = (list(conv[0].values()), list(conv[1].values()))\n",
    "    training_frame = train[lang_pair].get_dataframe(conversion_key[lang_pair], config[\"input_encoding\"], config[\"output_encoding\"])\n",
    "    testing_frame = test[lang_pair].get_dataframe(conversion_key[lang_pair], config[\"input_encoding\"], config[\"output_encoding\"])\n",
    "    baseline.compute_baseline(lang_a, lang_b, sounds, training_frame, testing_frame, baselines_path + \".txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify sound correspondences\n",
    "##### Based on output substitutions\n",
    "This shows the substitutions table in the notebook, and outputs it as LaTeX table to `RESULTS_DIR/subs.tex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T14:42:48.161412Z",
     "start_time": "2019-08-08T12:37:20.235Z"
    }
   },
   "outputs": [],
   "source": [
    "from visualize import visualize\n",
    "\n",
    "for lang_pair in lang_pairs:\n",
    "    visualize.show_output_substitutions(results_path[lang_pair], subs_st_path[lang_pair], subs_sp_path[lang_pair])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Based on context vector weights\n",
    "This works when word prediction with encoder-decoder has been run, which exports context vector weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors(139, 1, 400)\n",
      "input_raw(139, 1, 14, 28)\n",
      "target_raw(139, 1, 14, 29)\n",
      "After flatten\n",
      "vectors(139, 400)\n",
      "input_raw(139, 392)\n",
      "target_raw(139, 406)\n",
      "Number of words: 139\n",
      "Affinity propagation-0.2\n",
      "vectors_dist\n",
      " tant3 nakt nat tal last\n",
      " til3 stErkt3 sam3 sx3lt ski spul3 strom3 stot3 slik3 spel3 sprek3\n",
      " vErkiz3 rex3 rEn3 xev3 lex rur3 brad3\n",
      " kid3 morx3 bind3l mid3 Eiz3r mEis morx3 drom\n",
      " krEis sid3r3 krEip3 b3tal3 Eil3 r3is3\n",
      " brur vex3 buzEm vremt vrau uv3r vuts3l vur3 tuvux3 vex3 vol rup3 xrun\n",
      " vErxan drain ovErwin3 fert3x hoNerix b3drix3 rEip\n",
      " klim3 tek3 lEid3 kis3 kok3 blaz3 tudEk3 hErkEn3\n",
      " link3r blint lerar lint\n",
      " won3 wExan\n",
      " brand3 wrEiv3 t3r3x b3hers3 bEix3 x3borEnword3 vErbet3r3 b3xin3 vErxet3 vErbrand3 reparer3 vErbind3\n",
      " zikzEin zixvErzam3l3 yini sxEin3 afsnEid3 anzin zwErm\n",
      " hElft xEf hErfst\n",
      " zond3 zid3 x3zin z3\n",
      " hoN3r hart ton handuk hondErt\n",
      " zom3r mar mart arm\n",
      " drEk der dri dir\n",
      " hals hEmt hev3l hem3l hEld3r\n",
      " pat part\n",
      " x3wixt x3lEit x3wer inwik3l3 aNelExEnhEit\n",
      " spits inslap3 stan stok stomp ost3 stap3\n",
      " xord3l wort3l rot warhEit wEnd3 dr3p3l\n",
      " slEip3 sxer3 stEix3 sx3im\n",
      "\n",
      "input_dist\n",
      " tant3 nakt hart hals hEmt warhEit vur3 hErfst last lerar mart\n",
      " til3 sam3 rex3 tek3 t3r3x vex3 xev3 kok3 vex3\n",
      " vErkiz3 vErxan vErxet3 hErkEn3 vErbind3\n",
      " kid3 sid3r3 kis3 mid3 zid3 Eil3 Eiz3r\n",
      " stErkt3 strom3 sxEin3 stEix3 sprek3\n",
      " krEis wrEiv3 krEip3 slEip3\n",
      " brur buzEm uv3r xrun zwErm\n",
      " morx3 fert3x xord3l wort3l vuts3l morx3 dr3p3l\n",
      " klim3 blint slik3 r3is3\n",
      " bind3l brand3 bEix3 blaz3 brad3\n",
      " link3r yini lex lint\n",
      " won3 rEn3 rEip rur3 mEis rup3\n",
      " sx3lt sx3im\n",
      " ski drEk vremt vrau der dri dir drom arm\n",
      " zikzEin\n",
      " drain b3tal3 x3wixt x3zin x3lEit b3xin3 anzin x3wer\n",
      " hElft hEld3r hondErt\n",
      " ovErwin3\n",
      " hoNerix hoN3r zom3r\n",
      " zond3 lEid3 handuk wExan wEnd3\n",
      " zixvErzam3l3\n",
      " b3drix3 b3hers3\n",
      " pat tal part mar\n",
      " spul3 sxer3 spel3\n",
      " spits stot3 stan stok stomp stap3\n",
      " hev3l hem3l\n",
      " inslap3\n",
      " ton rot xEf nat vol ost3 z3\n",
      " x3borEnword3\n",
      " vErbet3r3 vErbrand3\n",
      " afsnEid3\n",
      " tuvux3 tudEk3\n",
      " inwik3l3\n",
      " reparer3\n",
      " aNelExEnhEit\n",
      "\n",
      "target_dist\n",
      " tant3 brur sx3lt nakt handuk x3zin last lint\n",
      " til3\n",
      " vErkiz3 won3 kok3\n",
      " kid3 hoNerix hoN3r hart hEmt wort3l part hErfst mart\n",
      " stErkt3 strom3 slEip3 stEix3 sprek3 stap3\n",
      " krEis drEk x3wixt vremt yini vrau uv3r dri drom xrun\n",
      " morx3 lEid3 bEix3 blint morx3\n",
      " sam3 vErxan b3tal3 b3xin3 tudEk3 hErkEn3\n",
      " klim3 brand3 blaz3 dr3p3l brad3\n",
      " bind3l zond3 xord3l hondErt\n",
      " link3r fert3x zom3r t3r3x ton mid3 der mar arm z3\n",
      " ski hElft hals xEf vol hEld3r\n",
      " zikzEin\n",
      " drain stan stok ost3 zwErm\n",
      " rex3 rEn3 xev3 rur3 vex3 x3wer rup3\n",
      " sid3r3 ovErwin3 vex3 hev3l kis3 Eil3\n",
      " tek3 wrEiv3 krEip3 sxer3 r3is3\n",
      " zixvErzam3l3\n",
      " b3drix3 b3hers3\n",
      " pat rot nat vuts3l rEip\n",
      " spul3 stot3 sxEin3 slik3 spel3\n",
      " spits x3lEit mEis stomp sx3im\n",
      " buzEm zid3 hem3l Eiz3r tal vur3\n",
      " inslap3 inwik3l3\n",
      " x3borEnword3\n",
      " lex dir lerar\n",
      " wExan anzin warhEit wEnd3\n",
      " vErbet3r3 vErxet3 vErbrand3 vErbind3\n",
      " afsnEid3 reparer3\n",
      " tuvux3\n",
      " aNelExEnhEit\n",
      "\n",
      "      Judgments         Gold  Precision    Recall         F\n",
      "0  vectors_dist   input_dist   0.288162  0.388022  0.330718\n",
      "1  vectors_dist  target_dist   0.266376  0.342663  0.299742\n",
      "2    input_dist  target_dist   0.390128  0.347442  0.367550\n",
      "\n",
      "\n",
      "Mean cluster size for different clustering methods:\n",
      "                 Method Threshold Context_min  Context_med Context_max  \\\n",
      "0  Affinity propagation       0.2           2          5.0          13   \n",
      "\n",
      "  Input_min  Input_med Input_max Target_min  Target_med Target_max  \n",
      "0         1        4.0        11          1         5.0         10  \n",
      "\n",
      "Direct distances between distance matrices\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cosine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c37a9cef88fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlang_pair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlang_pairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvisualize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_vectors_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlang_pair\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_encoding\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_encoding\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"results_dir\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git/prediction-histling/visualize/visualize.py\u001b[0m in \u001b[0;36mvisualize_weights\u001b[0;34m(context_vectors_path, langs, input_encoding, output_encoding, results_dir, sample, methods, thresholds)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;31m# Use cosine distance: magnitude should not play a role\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mdist_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\",\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\": \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cosine' is not defined"
     ]
    }
   ],
   "source": [
    "from visualize import visualize\n",
    "\n",
    "for lang_pair in lang_pairs:\n",
    "    visualize.visualize_weights(context_vectors_path[lang_pair], lang_pair, config[\"input_encoding\"], config[\"output_encoding\"], config[\"results_dir\"], sample=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phylogenetic tree reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clustering based on word prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T14:42:48.162205Z",
     "start_time": "2019-08-08T12:37:22.524Z"
    }
   },
   "outputs": [],
   "source": [
    "from tree import cluster\n",
    "\n",
    "# Cluster based on word prediction distances\n",
    "print(\"WP TREE:\\n\")\n",
    "cluster.cluster_languages(lang_pairs, distances_path, output_path=distances_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clustering based on baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T14:42:48.162967Z",
     "start_time": "2019-08-08T12:37:24.347Z"
    }
   },
   "outputs": [],
   "source": [
    "from tree import cluster\n",
    "\n",
    "# Source prediction baseline\n",
    "print(\"\\nSOURCE BASELINE TREE\")\n",
    "cluster.cluster_languages(lang_pairs, baselines_path, output_path=baselines_path + \"_source\", distance_col=2)\n",
    "# PMI-based baseline\n",
    "print(\"\\nPMI BASELINE TREE\")\n",
    "cluster.cluster_languages(lang_pairs, baselines_path, output_path=baselines_path + \"_pmi\", distance_col=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Draw tree from existing newick string (no distance calculcation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Improvised code to re-generate trees\n",
    "from ete3 import Tree, TreeStyle, NodeStyle, TextFace\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from util.config import config\n",
    "newick_string1 = \"((bul:0.15,(slv:0.11,hrv:0.11):0.04):0.04,((rus:0.11,(bel:0.1,ukr:0.1):0.01):0.07,(pol:0.15,(ces:0.08,slk:0.08):0.07):0.03):0.01);\"\n",
    "newick_string2 = \"(((bel:0.08,ukr:0.12):0.01,rus:0.12):0.03,(((slv:0.1,hrv:0.11):0.01,bul:0.18):0.07,(pol:0.17,(ces:0.1,slk:0.07):0.05):0.04):0.03);\"\n",
    "newick_string3 = \"((bul:0.29,((ces:0.24,slk:0.24):0.04,(slv:0.25,hrv:0.25):0.03):0.01):0.01,(pol:0.28,(rus:0.24,(bel:0.22,ukr:0.22):0.02):0.04):0.01);\"\n",
    "newick_string4 = \"((bel,rus,ukr),((hrv,slv),bul),((ces,slk),pol));\"\n",
    "\n",
    "ts = TreeStyle()\n",
    "ts.show_scale = False\n",
    "ts.show_leaf_name = False\n",
    "ts.force_topology = False\n",
    "ts.show_border = False\n",
    "ts.margin_top = ts.margin_bottom = ts.margin_right = ts.margin_left = 5\n",
    "ts.scale = 500\n",
    "ts.branch_vertical_margin= 10\n",
    "\n",
    "\n",
    "for i,newick_string in enumerate([newick_string1, newick_string2, newick_string3, newick_string4]):\n",
    "    if i==3: # last newick string without lengths, should be corrected\n",
    "        ts = TreeStyle()\n",
    "        ts.show_scale = False\n",
    "        ts.show_leaf_name = False\n",
    "        ts.force_topology = False\n",
    "        ts.show_border = False\n",
    "        ts.margin_top = ts.margin_bottom = ts.margin_right = ts.margin_left = 5\n",
    "        ts.scale = 50\n",
    "        ts.branch_vertical_margin= 10\n",
    "    # Load newick string into ete3 Tree object\n",
    "    tree = Tree(newick_string)\n",
    "    for node in tree.traverse():\n",
    "        node.set_style(config[\"ete_node_style\"])\n",
    "        if node.is_leaf():\n",
    "            # Add bit of extra space between leaf branch and leaf label\n",
    "            name_face = TextFace(f\" {node.name}\", fgcolor=\"black\", fsize=10)\n",
    "            node.add_face(name_face, column=0, position='branch-right')\n",
    "    print(f\"output/tree{i+1}.pdf\")\n",
    "    tree.render(f\"output/tree{i+1}.pdf\", tree_style=ts)\n",
    "    display(tree.render(f\"%%inline\", tree_style=ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cognate detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T14:42:48.163795Z",
     "start_time": "2019-08-08T12:37:26.572Z"
    }
   },
   "outputs": [],
   "source": [
    "from cognatedetection import cd\n",
    "\n",
    "### TODO: this part from previous code should not be executed:\n",
    "# print(\"Filter val/test sets on cognates.\")\n",
    "# Use only cognate pairs for validation and test\n",
    "# val[lang_pair] = val[lang_pair].filter_cognates()\n",
    "# test[lang_pair] = test[lang_pair].filter_cognates()\n",
    "# print(\"Val/test sizes after cognate filtering: \" + str(val[lang_pair].get_size()) + \"|\" + str(test[lang_pair].get_size()))\n",
    "\n",
    "\n",
    "print(\"Performing WP cognate detection using clustering...\")\n",
    "results_table = cd.cognate_detection_cluster(lang_pairs, config[\"results_dir\"], options, use_distance=\"prediction\")\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phylogenetic word prediction (experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T14:42:48.164558Z",
     "start_time": "2019-08-08T12:37:28.854Z"
    }
   },
   "outputs": [],
   "source": [
    "from util import utility\n",
    "from prediction import prediction\n",
    "\n",
    "\n",
    "# In phylogenetic mode, we created one feature matrix for all languages\n",
    "for lang_pair in lang_pairs:\n",
    "    conversion_key[lang_pair] = conversion_key_general\n",
    "\n",
    "voc_size = voc_size_general\n",
    "# For phylogenetic word prediction, create one feature matrix for all languages\n",
    "print(\"Create feature matrix for all language pairs.\")\n",
    "used_tokens = [[], []]\n",
    "tokens_set = [[], []]\n",
    "for lang_pair in lang_pairs:\n",
    "    # For phylogenetic word prediction, create one feature matrix for all languages\n",
    "    features_lp[lang_pair], max_len[lang_pair[0]], max_len[lang_pair[1]], _, _ = data.get_corpus_info([tsv_cognates_path_train + \".tsv\", tsv_cognates_path_valtest + \".tsv\"], lang_pair=lang_pair, input_encoding=config[\"input_encoding\"], output_encoding=config[\"output_encoding\"], feature_matrix_phon=feature_matrix_phon)\n",
    "    used_tokens[0] += list(features_lp[lang_pair][0].index)\n",
    "    used_tokens[1] += list(features_lp[lang_pair][1].index)\n",
    "\n",
    "tokens_set[0] = list(set(used_tokens[0]))\n",
    "tokens_set[1] = list(set(used_tokens[1]))\n",
    "if config[\"input_encoding\"] == \"character\":\n",
    "    features[0] = data.create_one_hot_matrix(tokens_set[0])\n",
    "elif config[\"input_encoding\"] == \"phonetic\":\n",
    "    features[0] = feature_matrix_phon.loc[tokens_set[0]]\n",
    "else:\n",
    "    print(\"Embedding encoding not possible in phylogenetic tree prediction.\")\n",
    "    return\n",
    "# Output encoding is always character\n",
    "features[1] = data.create_one_hot_matrix(tokens_set[1])\n",
    "voc_size_general[0] = features[0].shape[1]\n",
    "voc_size_general[1] = features[1].shape[1]\n",
    "conversion_key_general = data.create_conversion_key(features)\n",
    "plot_path_phyl = utility.create_path(config[\"results_dir\"], options, prefix=\"plot_\")\n",
    "\n",
    "config[\"export_weights\"] = False  # Turn off export of weights\n",
    "tree_string = \"((nld,deu),eng)\"  # unused at the moment\n",
    "if len(config[\"languages\"]) >= 3:\n",
    "    results_path_proto = utility.create_path(config[\"results_dir\"], options, prefix=\"proto_\")  # lang-pair independent path\n",
    "    prediction.word_prediction_phyl(config[\"languages\"], lang_pairs, tree_string, max_len, train, val, test, conversion_key_general, voc_size, results_path, results_path_proto, distances_path + \".txt\", context_vectors_path, plot_path_phyl, config[\"output_encoding\"], config)\n",
    "else:\n",
    "    print(\"Please supply 3 languages, the first 2 being more closely related than the last.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
